{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e716e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "tumor_097\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "first argument must be image or list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [13], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m patch \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(patch)\n\u001b[1;32m     25\u001b[0m patch \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(patch)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255\u001b[39m\n\u001b[0;32m---> 26\u001b[0m stat \u001b[38;5;241m=\u001b[39m \u001b[43mImageStat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m patch_mean\u001b[38;5;241m.\u001b[39mappend(stat\u001b[38;5;241m.\u001b[39mmean)\n\u001b[1;32m     28\u001b[0m patch_std\u001b[38;5;241m.\u001b[39mappend(stat\u001b[38;5;241m.\u001b[39mstd)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pathology/lib/python3.8/site-packages/PIL/ImageStat.py:39\u001b[0m, in \u001b[0;36mStat.__init__\u001b[0;34m(self, image_or_list, mask)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mh \u001b[38;5;241m=\u001b[39m image_or_list  \u001b[38;5;66;03m# assume it to be a histogram list\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mh, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfirst argument must be image or list\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbands \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mh) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m256\u001b[39m))\n",
      "\u001b[0;31mTypeError\u001b[0m: first argument must be image or list"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image, ImageStat\n",
    "import os\n",
    "\n",
    "path = '/data3/ian/dsmil-wsi/WSI/C16_training/single'\n",
    "dirs = os.listdir(path)\n",
    "mean_list = []\n",
    "std_list = []\n",
    "for d in dirs:\n",
    "    print(d)\n",
    "    d = os.path.join(path,d)\n",
    "    img_list = os.listdir(d)\n",
    "    img_mean = []\n",
    "    img_std = []\n",
    "    for img in img_list:\n",
    "        print(img)\n",
    "        img = os.path.join(d, img)\n",
    "        patches = os.listdir(img)\n",
    "        patch_mean = []\n",
    "        patch_std = []\n",
    "        for p in patches:\n",
    "            #print(patches)\n",
    "            patch = os.path.join(img, p)\n",
    "            patch = Image.open(patch)\n",
    "            patch = np.array(patch)/255\n",
    "            stat = ImageStat.Stat(patch)\n",
    "            patch_mean.append(stat.mean)\n",
    "            patch_std.append(stat.std)\n",
    "            \n",
    "        tmp = np.mean(patch_mean)\n",
    "        img_mean.append(tmp)\n",
    "\n",
    "        tmp = np.mean(patch_std)\n",
    "        img_std.append(tmp)\n",
    "         \n",
    "    tmp = np.mean(img_mean)\n",
    "    mean_list.append(tmp)\n",
    "    tmp = np.mean(img_std)\n",
    "    std_list.append(tmp)\n",
    "    \n",
    "print(np.mean(mean_list))\n",
    "print(np.mean(std_list))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe633478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[143.3711535395408, 92.78948102678571, 123.36892139668367]\n"
     ]
    }
   ],
   "source": [
    "path = '/data3/ian/dsmil-wsi/WSI/C16_training/single/1/tumor_001/149_271.jpeg'\n",
    "patch = Image.open(path)\n",
    "stat = ImageStat.Stat(patch)\n",
    "print(stat.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57766d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa5d40f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/data3/ian/dsmil-wsi/WSI/project_tiff/single/1'\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root, transform=transforms.ToTensor())\n",
    "#train_dataset = datasets.CIFAR10(root='dataset/', train=True, \n",
    "#                                 transform=transforms.ToTensor(), download=True)\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2d8d3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3434827, 2)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(train_dataset.imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06e65673",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_and_std(dataloader):\n",
    "    channels_sum, channels_squared_sum, num_batches = 0, 0, 0\n",
    "    for data, _ in dataloader:\n",
    "        # Mean over batch, height and width, but not over the channels\n",
    "        channels_sum += torch.mean(data, dim=[0,2,3])\n",
    "        channels_squared_sum += torch.mean(data**2, dim=[0,2,3])\n",
    "        num_batches += 1\n",
    "    \n",
    "    mean = channels_sum / num_batches\n",
    "\n",
    "    # std = sqrt(E[X^2] - (E[X])^2)\n",
    "    std = (channels_squared_sum / num_batches - mean ** 2) ** 0.5\n",
    "\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cef4afce",
   "metadata": {},
   "outputs": [],
   "source": [
    "m, s = get_mean_and_std(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dfb7b5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8865, 0.5624, 0.8367]) tensor([0.1441, 0.2491, 0.1156])\n"
     ]
    }
   ],
   "source": [
    "print(m,s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2bec9bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/data3/ian/dsmil-wsi/WSI/project_tiff/single/0'\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root, transform=transforms.ToTensor())\n",
    "#train_dataset = datasets.CIFAR10(root='dataset/', train=True, \n",
    "#                                 transform=transforms.ToTensor(), download=True)\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6be098ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "m, s = get_mean_and_std(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7802f071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9219, 0.6062, 0.8495]) tensor([0.1165, 0.2028, 0.1018])\n"
     ]
    }
   ],
   "source": [
    "print(m,s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1b974c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torchvision.datasets.cifar import CIFAR100\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(224),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "data_set = CIFAR100('./data/cifar', train=True, transform=transform, download=True)\n",
    "data_loader = DataLoader(data_set, batch_size=24, num_workers=8, shuffle=False)\n",
    "\n",
    "nb_samples = 0.\n",
    "channel_mean = torch.zeros(3)\n",
    "channel_std = torch.zeros(3)\n",
    "for images, targets in tqdm(data_loader):\n",
    "    # scale image to be between 0 and 1\n",
    "    N, C, H, W = images.shape[:4]\n",
    "    data = images.view(N, C, -1)\n",
    "\n",
    "    channel_mean += data.mean(2).sum(0)\n",
    "    channel_std += data.std(2).sum(0)\n",
    "    nb_samples += N\n",
    "\n",
    "channel_mean /= nb_samples\n",
    "channel_std /= nb_samples\n",
    "print(channel_mean, channel_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a9b58a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import shutil\n",
    "\n",
    "img_path = '/data3/ian/dsmil-wsi/WSI/project_tiff/single/0'\n",
    "store_path = '/data3/ian/dsmil-wsi/WSI/project_tiff/train/0'\n",
    "dir_list = os.listdir(img_path)\n",
    "for d in dir_list:\n",
    "    dir_path = os.path.join(img_path, d)\n",
    "    files = os.listdir(dir_path)\n",
    "    for f in files:\n",
    "        file = os.path.join(dir_path,f)\n",
    "        des = os.path.join(store_path,d+'_'+f)\n",
    "        shutil.copyfile(file, des)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
